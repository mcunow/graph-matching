{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath(\"/netscratch/cunow/graph-matching\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://pypi-cache/index, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pot in /usr/local/lib/python3.10/dist-packages (0.9.4)\n",
      "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from pot) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.6 in /usr/local/lib/python3.10/dist-packages (from pot) (1.12.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://pypi-cache/index, https://pypi.ngc.nvidia.com\n",
      "Collecting wandb\n",
      "  Downloading http://pypi-cache/index/wandb/wandb-0.18.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m345.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading http://pypi-cache/index/docker-pycreds/docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Downloading http://pypi-cache/index/gitpython/GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m368.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.24.4)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Downloading http://pypi-cache/index/sentry-sdk/sentry_sdk-2.15.0-py2.py3-none-any.whl (310 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.0/311.0 kB\u001b[0m \u001b[31m336.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting setproctitle (from wandb)\n",
      "  Downloading http://pypi-cache/index/setproctitle/setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (68.2.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading http://pypi-cache/index/gitdb/gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m299.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading http://pypi-cache/index/smmap/smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
      "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.15.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.18.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  import torch_geometric\n",
    "except:\n",
    "  os.system(\"pip install pyg-lib torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}+${CUDA}.html\")\n",
    "  os.system(\"pip install torch-geometric\")\n",
    "    \n",
    "try:\n",
    "  import rdkit\n",
    "except:\n",
    "  os.system(\"pip install rdkit\")\n",
    "\n",
    "try:\n",
    "  import pot\n",
    "except:\n",
    "  os.system(\"pip install pot\")\n",
    "\n",
    "try:\n",
    "  import seaborn\n",
    "except:\n",
    "  os.system(\"pip install seaborn\")\n",
    "try:\n",
    "  import wandb # need to do this before chaning CWD\n",
    "except:\n",
    "  os.system(\"pip install wandb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/usr/local/lib/python3.10/dist-packages/wandb']\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gnn\n",
    "from rdkit import Chem\n",
    "#from rdkit.Chem import Draw\n",
    "import utils\n",
    "import util_metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import Data,Batch\n",
    "from torch_geometric.utils import to_dense_adj,to_dense_batch,get_embeddings\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "import vgae\n",
    "import copy\n",
    "import visualize\n",
    "import wandb\n",
    "import utils\n",
    "import matching\n",
    "from decoder import Decoder\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "print(wandb.__path__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path='../data/QM9_canonical.pkl'\n",
    "with open(file_path, 'rb') as file:\n",
    "    dataset_smiles = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../data/dataset.pkl.gz', 'rb') as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:sxfa9vwu) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>grad/decoder_gradients</td><td>█▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>grad/encoder_gradients</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>inference/Novelty</td><td>█▆▁▁▁▁▁▃▁▁▁▁▁▁▃▁▁▁▃▃▃▃▁▃▃▁▁▁▃▃▁▃▁▁▃▃▃▃▃▃</td></tr><tr><td>inference/Uniqueness</td><td>▁▂▅▅▆▆▄▅▅▅▅▆▅▄▅▅▅▅▃▄▃▄▅▄▄▄▄▄▄▄▄▄▄▆▄▇▇█▆▄</td></tr><tr><td>inference/Validity</td><td>▃██▃▁▁▁▂▂▂▃▄▄▅▅▆▆▆▆▆▇▇▇▇████████████████</td></tr><tr><td>train/kl_loss</td><td>█▆▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/matched_loss</td><td>███▇▇▂▂▂▁▂▂▁▁▂▂▁▁▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>train/num_node_pred_loss</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/unmatched_loss</td><td>█▂▂▂▂▁▂▁▂▂▂▁▂▁▂▁▂▂▂▂▂▁▁▂▂▂▁▁▁▂▁▂▂▁▂▁▁▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>grad/decoder_gradients</td><td>0.07842</td></tr><tr><td>grad/encoder_gradients</td><td>0.00253</td></tr><tr><td>inference/Novelty</td><td>0.0</td></tr><tr><td>inference/Uniqueness</td><td>0.0005</td></tr><tr><td>inference/Validity</td><td>1</td></tr><tr><td>train/kl_loss</td><td>0.0</td></tr><tr><td>train/matched_loss</td><td>0.265</td></tr><tr><td>train/num_node_pred_loss</td><td>0.00302</td></tr><tr><td>train/unmatched_loss</td><td>0.265</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">polished-firefly-21</strong> at: <a href='https://wandb.ai/m-cunow/Graph%20Matching/runs/sxfa9vwu' target=\"_blank\">https://wandb.ai/m-cunow/Graph%20Matching/runs/sxfa9vwu</a><br/> View project at: <a href='https://wandb.ai/m-cunow/Graph%20Matching' target=\"_blank\">https://wandb.ai/m-cunow/Graph%20Matching</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241007_110059-sxfa9vwu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:sxfa9vwu). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/netscratch/cunow/graph-matching/src/wandb/run-20241008_112221-mxyvmg6h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/m-cunow/Graph%20Matching/runs/mxyvmg6h' target=\"_blank\">smart-capybara-22</a></strong> to <a href='https://wandb.ai/m-cunow/Graph%20Matching' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/m-cunow/Graph%20Matching' target=\"_blank\">https://wandb.ai/m-cunow/Graph%20Matching</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/m-cunow/Graph%20Matching/runs/mxyvmg6h' target=\"_blank\">https://wandb.ai/m-cunow/Graph%20Matching/runs/mxyvmg6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/m-cunow/Graph%20Matching/runs/mxyvmg6h?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f0dedbc5d50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"c4476f3ae06843fcc1472fbd0a5dadaceabd7557\")\n",
    "wandb.init(\n",
    "    project=\"Graph Matching\",\n",
    "    config={\n",
    "        \"epochs\": 500,\n",
    "        \"batch_size\": 256,\n",
    "        \"encoder_norm\":\"graph\",\n",
    "        \"lr\": 5e-6,\n",
    "        \"dropout\": 0.05,\n",
    "        \"sample_size\":10000,\n",
    "        \"dataset_size\": 129428,\n",
    "        \"latent_dim\": 50\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dims=wandb.config[\"latent_dim\"]\n",
    "edge_dim=4\n",
    "node_dim=4\n",
    "train_loader=DataLoader(dataset,256,shuffle=True)\n",
    "matcher=matching.NaiveMatcher()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "encoder=gnn.GINE(in_channels=node_dim,hidden_channels=[16,32,64,128],out_channels=128,norm=\"graph\",num_layers=4,\n",
    "                  act=\"leakyrelu\",edge_dim=4,dropout=0.1).to(device)\n",
    "#decoder=gnn_decoder.Generator_Decoder(latent_dim=latent_dims,node_dim=node_dim,edge_dim=edge_dim,num_layers=4).to(device)\n",
    "decoder=Decoder(latent_dims).to(device)\n",
    "matcher=matching.NaiveMatcher()\n",
    "\n",
    "vgae_model=vgae.VGAE(encoder=encoder,decoder=decoder,latent_dims=latent_dims,embedding=\"graph\",eval=False).to(device)\n",
    "#vgae_model.set_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 506/506 [04:21<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9917 0.00010083694665725522 1.1102230246251565e-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 506/506 [04:23<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0001 1.1102230246251565e-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 506/506 [04:21<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9981 0.0006011421701232341 1.1102230246251565e-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 506/506 [04:25<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9344 0.0005351027397260274 2.220446049250313e-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 506/506 [04:24<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.917 0.0005452562704471102 2.220446049250313e-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 506/506 [04:23<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9139 0.000547105810263705 2.220446049250313e-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 506/506 [04:21<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9202 0.0004346881112801565 2.220446049250313e-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 216/506 [01:52<02:29,  1.94it/s]"
     ]
    }
   ],
   "source": [
    "vgae_model.train()\n",
    "optimizer = torch.optim.Adam(vgae_model.parameters(), lr=1e-5,weight_decay=1e-5)\n",
    "kl_loss_ls,matched_loss_ls,unmatched_loss_ls,num_loss_ls=[],[],[],[]\n",
    "alpha=0.01\n",
    "beta=1.\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for epoch in range(wandb.config[\"epochs\"]):\n",
    "    vgae_model.train()\n",
    "    for data in tqdm(train_loader):\n",
    "      data = data.to(device)\n",
    "      optimizer.zero_grad()\n",
    "      data_rec,mu,logvar,_,pred_num= vgae_model(data)\n",
    "      num_nodes=torch.bincount(data.batch).to(torch.float32)\n",
    "      num_loss=alpha*F.mse_loss(pred_num,num_nodes)\n",
    "\n",
    "      matched_loss,unmatched_loss=matcher.diffusion_matching(data,data_rec,test=True)\n",
    "      kl_loss=beta*vgae_model.kl_loss(mu,logvar)\n",
    "      loss=matched_loss+kl_loss+num_loss\n",
    "      loss.backward()\n",
    "      encoder_grad,decoder_grad=compute_gradients(vgae_model)\n",
    "      optimizer.step()\n",
    "      #Log data and evaluate reconstruction quality\n",
    "      #valid_rec,num_rec=util_metrics.evaluate_reconstruction(data,data_rec)\n",
    "      wandb.log({\"train/matched_loss\":matched_loss,\"train/unmatched_loss\":unmatched_loss,\n",
    "              \"train/kl_loss\":kl_loss,\"train/num_node_pred_loss\":num_loss})#,\"valid_rec\":valid_rec,\"frac_rec\":num_rec})\n",
    "      wandb.log({\"grad/encoder_gradients\":encoder_grad,\"grad/decoder_gradients\":decoder_grad})\n",
    "      optimizer.step()\n",
    "    #Generate samples\n",
    "    if epoch%5==0:\n",
    "        path=f\"../models/vgae_model_{epoch}.pth\"\n",
    "        torch.save(vgae_model.state_dict(), path)\n",
    "    vgae_model.eval()\n",
    "    sample=vgae_model.sample(wandb.config[\"sample_size\"])    \n",
    "    validity,unique,novelty,_=util_metrics.compute_metrics(sample,dataset_smiles)\n",
    "    print(validity,unique,novelty)\n",
    "    wandb.log({\"inference/Validity\":validity,\"inference/Uniqueness\":unique,\"inference/Novelty\":novelty})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compute_gradients(model):\n",
    "    \"\"\"\n",
    "    Computes the gradients for the encoder and decoder separately and calculates their norms.\n",
    "\n",
    "    Args:\n",
    "        model: The VAE model containing encoder and decoder.\n",
    "\n",
    "    Returns:\n",
    "        encoder_gradients: Gradients of the encoder parameters.\n",
    "        decoder_gradients: Gradients of the decoder parameters.\n",
    "        encoder_norm: Norm of the encoder gradients.\n",
    "        decoder_norm: Norm of the decoder gradients.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    encoder_norm = 0.0\n",
    "    decoder_norm = 0.0\n",
    "\n",
    "    # Loop through model parameters\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.grad is not None:  # Ensure the gradients exist\n",
    "            if 'encoder' in name:\n",
    "\n",
    "                encoder_norm += param.grad.data.norm(2).item() ** 2  # L2 norm\n",
    "            elif 'decoder' in name:\n",
    "                decoder_norm += param.grad.data.norm(2).item() ** 2  # L2 norm\n",
    "\n",
    "    # Take the square root of the sums to get the final norms\n",
    "    encoder_norm = encoder_norm ** 0.5\n",
    "    decoder_norm = decoder_norm ** 0.5\n",
    "\n",
    "    return encoder_norm, decoder_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import  degree\n",
    "DEVICE=\"cpu\"\n",
    "def dataset_to_degree_bin(train_dataset):\n",
    "  \"\"\"\n",
    "  Convert a dataset to a histogram of node degrees (in-degrees).\n",
    "  Load from file if available; otherwise, compute from the dataset.\n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "  # Compute the maximum in-degree in the training data.\n",
    "  max_degree = -1\n",
    "  for data in train_dataset:\n",
    "    data = data\n",
    "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
    "    max_degree = max(max_degree, int(d.max()))\n",
    "\n",
    "  # Create an empty histogram for degrees.\n",
    "  deg = torch.zeros(max_degree + 1, dtype=torch.long, device=DEVICE)\n",
    "\n",
    "  # Populate the histogram with data from the dataset.\n",
    "  for data in train_dataset:\n",
    "    data = data.to(DEVICE)\n",
    "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
    "    deg += torch.bincount(d, minlength=deg.numel())\n",
    "\n",
    "\n",
    "  return deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_to_degree_bin(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand((8,6)).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Example tensor of shape (n, 9, 9, 4)\n",
    "n = 3  # Example batch size\n",
    "tensor = torch.rand((9, 9, 4))\n",
    "\n",
    "# Create a new tensor with an additional 0 at the start of the fourth dimension\n",
    "zeros = torch.zeros(( 9, 9, 1))\n",
    "expanded_tensor = torch.cat((zeros, tensor), dim=2)\n",
    "\n",
    "print(expanded_tensor.shape)  # Should be (n, 9, 9, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgae_model.eval()\n",
    "sample=vgae_model.sample(wandb.config[\"sample_size\"])    \n",
    "validity,unique,novelty,_=util_metrics.compute_metrics(sample,dataset_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=\"YOUR/PATH/HERE\"\n",
    "torch.save(vgae_model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Samples. Compute fraction of valid, unique, and novel molecules. Return SMILES representation of all novel SMILES.\n",
    "Plot generated molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgae_model.eval()\n",
    "sample=vgae_model.sample(1000)\n",
    "validity,unique,novel,smiles_list=util_metrics.compute_metrics(sample,dataset_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "mol_list = [Chem.MolFromSmiles(smiles) for smiles in list(smiles_list)]\n",
    "Draw.MolsToGridImage(mol_list[:50], molsPerRow=10, subImgSize=(400,400),maxMols=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
